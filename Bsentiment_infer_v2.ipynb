{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cf1fee3b182244dc9f4665b0aa724f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58d8a7a7534d4fbaa55837922beea0a7",
              "IPY_MODEL_d9708ba7e6964b17b666d57b30311c62",
              "IPY_MODEL_c7fef9d05af145fd96d90f2516128d4f"
            ],
            "layout": "IPY_MODEL_dbc99a9c7a9647f290d7800092cfe2ed"
          }
        },
        "58d8a7a7534d4fbaa55837922beea0a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f90e5691e4f3444599dbcbd98335f056",
            "placeholder": "​",
            "style": "IPY_MODEL_7165bd7ab6d94ab9ac0f0e401bf76ee0",
            "value": "config.json: 100%"
          }
        },
        "d9708ba7e6964b17b666d57b30311c62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cd2dce7bc2c4299b69a33d7b287f1b9",
            "max": 491,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a444ef8008f94f83a2f2adb6cd1d8dab",
            "value": 491
          }
        },
        "c7fef9d05af145fd96d90f2516128d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a08fa501ba804814a2ef428d0dd3c6eb",
            "placeholder": "​",
            "style": "IPY_MODEL_0d2dfd791ca0449b98d7e01a2ceb8c47",
            "value": " 491/491 [00:00&lt;00:00, 19.5kB/s]"
          }
        },
        "dbc99a9c7a9647f290d7800092cfe2ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f90e5691e4f3444599dbcbd98335f056": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7165bd7ab6d94ab9ac0f0e401bf76ee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cd2dce7bc2c4299b69a33d7b287f1b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a444ef8008f94f83a2f2adb6cd1d8dab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a08fa501ba804814a2ef428d0dd3c6eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d2dfd791ca0449b98d7e01a2ceb8c47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43e19201019442629bef678bdaf35654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e06f2e9478a34b48b1f7fe18b211f757",
              "IPY_MODEL_2188428d7f474a85823c5b07796f2432",
              "IPY_MODEL_2e22c07598874da386abe6933f153a13"
            ],
            "layout": "IPY_MODEL_fe5ebf85489f46e3ac68e2f4570a3e40"
          }
        },
        "e06f2e9478a34b48b1f7fe18b211f757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42c331d08e4a46deb79604fad9fd381d",
            "placeholder": "​",
            "style": "IPY_MODEL_682364163bb54b47ab3b7e0e9301d911",
            "value": "vocab.txt: 100%"
          }
        },
        "2188428d7f474a85823c5b07796f2432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed14edfcd1324d20976f58f225ee8c19",
            "max": 2237676,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b1b9f49589a4376be1a8d10cf83d37b",
            "value": 2237676
          }
        },
        "2e22c07598874da386abe6933f153a13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8aac3ca6c1484065bdf67984992ad112",
            "placeholder": "​",
            "style": "IPY_MODEL_5b3487a2c8e64401bb26e0a3b9c9854f",
            "value": " 2.24M/2.24M [00:00&lt;00:00, 5.87MB/s]"
          }
        },
        "fe5ebf85489f46e3ac68e2f4570a3e40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42c331d08e4a46deb79604fad9fd381d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "682364163bb54b47ab3b7e0e9301d911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed14edfcd1324d20976f58f225ee8c19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b1b9f49589a4376be1a8d10cf83d37b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8aac3ca6c1484065bdf67984992ad112": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b3487a2c8e64401bb26e0a3b9c9854f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OPdsjVE-8YF3",
        "outputId": "36a97e1f-c9d3-4487-9361-35edefe6013b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bnlp_toolkit\n",
            "  Downloading bnlp_toolkit-4.0.0-py3-none-any.whl (22 kB)\n",
            "Collecting sentencepiece (from bnlp_toolkit)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (4.3.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (1.11.3)\n",
            "Collecting sklearn-crfsuite (from bnlp_toolkit)\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (4.66.1)\n",
            "Collecting ftfy (from bnlp_toolkit)\n",
            "  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting emoji==1.7.0 (from bnlp_toolkit)\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (2.31.0)\n",
            "Collecting wcwidth<0.3.0,>=0.2.12 (from ftfy->bnlp_toolkit)\n",
            "  Downloading wcwidth-0.2.12-py2.py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->bnlp_toolkit) (6.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp_toolkit) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp_toolkit) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp_toolkit) (2023.6.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp_toolkit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp_toolkit) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp_toolkit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp_toolkit) (2023.7.22)\n",
            "Collecting python-crfsuite>=0.8.3 (from sklearn-crfsuite->bnlp_toolkit)\n",
            "  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (1.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (0.9.0)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171031 sha256=56b4a8ec559530de42dcb2542448f538b43fa4f914a9edcba4df05a23c2e873e\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/8a/8c/315c9e5d7773f74b33d5ed33f075b49c6eaeb7cedbb86e2cf8\n",
            "Successfully built emoji\n",
            "Installing collected packages: wcwidth, sentencepiece, python-crfsuite, emoji, sklearn-crfsuite, ftfy, bnlp_toolkit\n",
            "  Attempting uninstall: wcwidth\n",
            "    Found existing installation: wcwidth 0.2.10\n",
            "    Uninstalling wcwidth-0.2.10:\n",
            "      Successfully uninstalled wcwidth-0.2.10\n",
            "Successfully installed bnlp_toolkit-4.0.0 emoji-1.7.0 ftfy-6.1.3 python-crfsuite-0.9.9 sentencepiece-0.1.99 sklearn-crfsuite-0.3.6 wcwidth-0.2.12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "wcwidth"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting schedule\n",
            "  Downloading schedule-1.2.1-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: schedule\n",
            "Successfully installed schedule-1.2.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install bnlp_toolkit\n",
        "!pip install schedule\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Requirements:\n",
        "##### The following two cells imports the libraries, and prepares the model and other files/folders required to run the sentiment prediction program.\n",
        "\n",
        "##### Pleae reffer to the comments for adjusting the variables and, commenenting out unnecessary lines, based the system used for running this code"
      ],
      "metadata": {
        "id": "SrWuuauxdcfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from bnlp import NLTKTokenizer\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import datetime\n",
        "import pytz\n",
        "import os\n",
        "import os.path\n",
        "import re\n",
        "import threading\n",
        "import schedule\n",
        "import time\n",
        "from zipfile import ZipFile\n",
        "from bnlp import BengaliCorpus as corpus\n",
        "from bnlp import CleanText\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# please comment out the following three lines if not running this file on colab\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYDaxuay3BmM",
        "outputId": "8c30aac7-61ad-4865-d4c5-f1b1a16eb6df"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "punkt not found. downloading...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MakeModel(nn.Module):\n",
        "  def __init__(self,model,k):\n",
        "    super(MakeModel,self).__init__()\n",
        "    self.bert_model=model\n",
        "    self.lin_layer=nn.Linear(768,k)\n",
        "\n",
        "  def forward(self,input_ids,attention_mask):\n",
        "    out_vect=self.bert_model(input_ids=input_ids,attention_mask=attention_mask)\n",
        "    lin_op=self.lin_layer(out_vect.last_hidden_state[:,0,:])\n",
        "    return F.softmax(lin_op)\n",
        "\n",
        "\n",
        "bnltk = NLTKTokenizer()\n",
        "os.mkdir('results')\n",
        "DEVICE=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# either of the following two finetuned models can be used\n",
        "\n",
        "# model 1\n",
        "# model_name = 'csebuetnlp/banglabert'\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# PATH = '/content/drive/MyDrive/Bangla_SA/bsenti_model3.pt'       # please adjust this path based on model's storage location\n",
        "# model = torch.load(PATH)\n",
        "# model.to(DEVICE)\n",
        "\n",
        "# model 2\n",
        "model_name = 'sagorsarker/bangla-bert-base'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "PATH = '/content/drive/MyDrive/Bangla_SA/bsenti_model.pt'       # please adjust this path based on model's storage location\n",
        "model = torch.load(PATH)\n",
        "model.to(DEVICE)\n",
        "\n",
        "# please modify the below two paths accorsing to your system\n",
        "dir_path_in = '/content'           # stores input: directory in which the json files of news articles will be present\n",
        "dir_path_out = '/content/results'           # stores output: oudirectory in which the generated sentiment analysis json files are present\n",
        "\n",
        "# the follwoing two lines extracts a sample of 100 news articles json files and adds them to the input directory of news articles\n",
        "# comment out the following two lines if you don't want to extract files from news_sample.zip or don't have any such zipfile\n",
        "articles_fl = \"news_sample.zip\"    # you may also modify this varible if you have any other zipfile\n",
        "with ZipFile(articles_fl, 'r') as zObject:\n",
        "  zObject.extractall(path=dir_path_in)\n",
        "\n",
        "\n",
        "files_list_in = os.listdir(dir_path_in)\n",
        "files_list_out = os.listdir(dir_path_out)\n",
        "\n",
        "stopwords = corpus.stopwords\n",
        "punct = [p for p in corpus.punctuations]\n",
        "punct2 = punct[:-2]\n",
        "bsw_df = pd.read_excel('stopwords_bangla.xlsx')\n",
        "sw2 = list(bsw_df['words'])\n",
        "stopwords.extend(sw2)\n",
        "stopwords = sorted(list(set(stopwords)))\n",
        "clean_text = CleanText(\n",
        "   fix_unicode=True,\n",
        "   unicode_norm=True,\n",
        "   unicode_norm_form=\"NFKC\",\n",
        "   remove_url=True,\n",
        "   remove_email=True,\n",
        "   remove_emoji=True,\n",
        "   remove_number=True,\n",
        "   remove_digits=True,\n",
        "   remove_punct=False,\n",
        "   replace_with_url=\" \",\n",
        "   replace_with_email=\" \",\n",
        "   replace_with_number=\" \",\n",
        "   replace_with_digit=\" \")"
      ],
      "metadata": {
        "id": "BcWqPN-WoP-c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "cf1fee3b182244dc9f4665b0aa724f68",
            "58d8a7a7534d4fbaa55837922beea0a7",
            "d9708ba7e6964b17b666d57b30311c62",
            "c7fef9d05af145fd96d90f2516128d4f",
            "dbc99a9c7a9647f290d7800092cfe2ed",
            "f90e5691e4f3444599dbcbd98335f056",
            "7165bd7ab6d94ab9ac0f0e401bf76ee0",
            "4cd2dce7bc2c4299b69a33d7b287f1b9",
            "a444ef8008f94f83a2f2adb6cd1d8dab",
            "a08fa501ba804814a2ef428d0dd3c6eb",
            "0d2dfd791ca0449b98d7e01a2ceb8c47",
            "43e19201019442629bef678bdaf35654",
            "e06f2e9478a34b48b1f7fe18b211f757",
            "2188428d7f474a85823c5b07796f2432",
            "2e22c07598874da386abe6933f153a13",
            "fe5ebf85489f46e3ac68e2f4570a3e40",
            "42c331d08e4a46deb79604fad9fd381d",
            "682364163bb54b47ab3b7e0e9301d911",
            "ed14edfcd1324d20976f58f225ee8c19",
            "0b1b9f49589a4376be1a8d10cf83d37b",
            "8aac3ca6c1484065bdf67984992ad112",
            "5b3487a2c8e64401bb26e0a3b9c9854f"
          ]
        },
        "outputId": "4d80c7bf-c9bd-4d55-be73-66783e02c0c6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/491 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf1fee3b182244dc9f4665b0aa724f68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/2.24M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43e19201019442629bef678bdaf35654"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code for output generation"
      ],
      "metadata": {
        "id": "MYaJFVGtdJyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment(sent,tokenizer,model):\n",
        "  tokenized_path = tokenizer(sent,truncation=True,padding=True,max_length=500,return_tensors='pt').to(DEVICE)\n",
        "  input_ids,attn_mask = tokenized_path['input_ids'],tokenized_path['attention_mask']\n",
        "  out_vals=model(input_ids,attn_mask)\n",
        "  labl=torch.argmax(out_vals,1)\n",
        "  out_list=out_vals.detach().cpu().numpy().tolist()\n",
        "  label_dict = {0:'Negative', 1:'Positive', 2:'Neutral'}\n",
        "  output_dict=dict()\n",
        "  for i in range(len(out_list[0])):\n",
        "    output_dict[label_dict[i]]= round(out_list[0][i],3)\n",
        "  return output_dict\n",
        "\n",
        "\n",
        "def predict(text,cat):\n",
        "  sents = bnltk.sentence_tokenize(text)\n",
        "  res_dict = dict()\n",
        "  for st in sents:\n",
        "    curr_dict2 = get_sentiment(st,tokenizer,model)\n",
        "    if len(res_dict.keys()) == 0:\n",
        "      res_dict = curr_dict2.copy()\n",
        "    else:\n",
        "      for k in curr_dict2.keys():\n",
        "        res_dict[k] = res_dict[k] + curr_dict2[k]\n",
        "  for k in res_dict.keys():\n",
        "    res_dict[k] = round((res_dict[k]/len(sents)),3)\n",
        "  curr_dict2 = get_sentiment(text,tokenizer,model)\n",
        "  for k in curr_dict2.keys():\n",
        "    res_dict[k] = res_dict[k] + curr_dict2[k]\n",
        "  for k in res_dict.keys():\n",
        "    res_dict[k] = round((res_dict[k]/2),3)\n",
        "  senti, val = None, -1\n",
        "  for k in res_dict.keys():\n",
        "    if res_dict[k] > val:\n",
        "      val = res_dict[k]\n",
        "      senti = k\n",
        "  res_dict['Sentiment'] = senti\n",
        "  res_dict['Category'] = cat\n",
        "  current_time = datetime.datetime.now(pytz.timezone('Asia/Kolkata'))\n",
        "  date = str(current_time.day) + '/' + str(current_time.month) + '/' + str(current_time.year)\n",
        "  time = str(current_time.hour) + ':' + str(current_time.minute) + ':' + str(current_time.second)\n",
        "  res_dict['Date'] = date\n",
        "  res_dict['Time of generation'] = time\n",
        "  return res_dict\n",
        "\n",
        "\n",
        "def add_to_result(fl_name,content):\n",
        "  text = content['title'] + ' । ' + content['body']\n",
        "  pr_text = clean_text(text)\n",
        "  tokens = pr_text.split()\n",
        "  tokens = [t for t in tokens if t not in stopwords]\n",
        "  tokens = [t for t in tokens if t not in punct2]\n",
        "  pr_text2 = ' '.join(tokens)\n",
        "  pr_text2 = str(pr_text2)\n",
        "  cat = content['label']\n",
        "  res_dict = predict(pr_text2,cat)\n",
        "  fl_dir = dir_path_out + '/' + fl_name\n",
        "  with open(fl_dir, \"w\") as output:\n",
        "    json.dump(res_dict, output, indent=2)\n",
        "  print(f'\\nPredicted the sentiment of {fl_name} and added to the output directory !!! ')\n",
        "\n",
        "\n",
        "def download_result():       # call this function if running this code on colab and need to download all output files zipping together\n",
        "  zf = ZipFile(\"outputs.zip\", \"w\")\n",
        "  for dirname, subdirs, fles in os.walk(dir_path_out):\n",
        "      zf.write(dirname)\n",
        "      for filename in fles:\n",
        "          zf.write(os.path.join(dirname, filename))\n",
        "  zf.close()\n",
        "  files.download('/content/outputs.zip')\n",
        "\n",
        "\n",
        "def run_prediction():\n",
        "  files_list_in = os.listdir(dir_path_in)\n",
        "  files_list_in = [fl for fl in files_list_in if len(re.findall('\\.json',fl))==1]\n",
        "  files_list_out = os.listdir(dir_path_out)\n",
        "  new_files = list(set(files_list_in) - set(files_list_out))\n",
        "  n = len(new_files)\n",
        "  if n > 0:\n",
        "    i, j = 0, 0\n",
        "    while i < n:\n",
        "      threadpool = []\n",
        "      while i < n and j < 5:\n",
        "        fl = new_files[i]\n",
        "        fl_path = dir_path_in + '/' + fl\n",
        "        with open(fl_path, encoding='utf-8') as f:\n",
        "          content = json.load(f)\n",
        "        t = threading.Thread(target=add_to_result, args=(fl,content,))\n",
        "        threadpool.append(t)\n",
        "        i += 1\n",
        "        j += 1\n",
        "      for t in threadpool:\n",
        "        t.start()\n",
        "      for t in threadpool:\n",
        "        t.join()\n",
        "      if i < n:\n",
        "        j = 0\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "  count = 5  # modify the minutes count as per the requirement of how frequently the prediction function should be executed\n",
        "  schedule.every(count).minutes.do(run_prediction)\n",
        "  #schedule.every().hour.do(run_prediction)\n",
        "  while True:\n",
        "    schedule.run_pending()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8dBtJSrh9USC",
        "outputId": "d2c0eb07-9d52-4691-e736-61abe813f615"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicted the sentiment of a41.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a8.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a99.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a30.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a90.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a20.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a61.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a58.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a29.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a78.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a40.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a46.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a49.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a26.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a71.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a93.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a36.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a94.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a33.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a85.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a95.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a60.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a51.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a34.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a77.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a43.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a10.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a70.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a18.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a9.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a63.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a66.json and added to the output directory !!! \n",
            "Predicted the sentiment of a69.json and added to the output directory !!! \n",
            "\n",
            "\n",
            "Predicted the sentiment of a4.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a84.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a81.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a82.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a91.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a45.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a92.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a24.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a54.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a73.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a12.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a64.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a22.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a39.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a25.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a31.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a80.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a96.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a1.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a89.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a87.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a62.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a47.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a2.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a14.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a17.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a38.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a75.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a5.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a27.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a3.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a32.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a68.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a79.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a48.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a83.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a21.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a56.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a37.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a97.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a50.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a42.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a44.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a100.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a52.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a74.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a19.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a28.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a72.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a16.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a65.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a11.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a15.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a7.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a88.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a23.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a53.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a13.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a76.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a67.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a98.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a57.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a35.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a86.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a55.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a6.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a59.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of z6.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of z2.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of z3.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of z7.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of z1.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of z5.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of z4.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of z8.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of z10.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of z9.json and added to the output directory !!! \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4679afcbd072>\u001b[0m in \u001b[0;36m<cell line: 93>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;31m#schedule.every().hour.do(run_prediction)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mschedule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pending\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/schedule/__init__.py\u001b[0m in \u001b[0;36mrun_pending\u001b[0;34m()\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdefault\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mdefault_scheduler\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \"\"\"\n\u001b[0;32m--> 822\u001b[0;31m     \u001b[0mdefault_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pending\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/schedule/__init__.py\u001b[0m in \u001b[0;36mrun_pending\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mbetween\u001b[0m \u001b[0mbut\u001b[0m \u001b[0monly\u001b[0m \u001b[0monce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mrunnable_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunnable_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run this to download a zip of the predicted files, if running code in google colab\n",
        "download_result()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "f_gyPMh4lkkr",
        "outputId": "7202504a-b661-4867-9415-d358821e1472"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_aeb9c3e8-7c79-4204-a464-4388e446f7a3\", \"outputs.zip\", 33077)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}