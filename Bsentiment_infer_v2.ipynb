{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPdsjVE-8YF3",
        "outputId": "73f07521-4596-449a-87dc-fb197ab2aa8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bnlp_toolkit in /usr/local/lib/python3.10/dist-packages (4.0.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (0.1.99)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (4.3.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (1.11.3)\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (0.3.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (4.66.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (6.1.3)\n",
            "Requirement already satisfied: emoji==1.7.0 in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (1.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bnlp_toolkit) (2.31.0)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->bnlp_toolkit) (0.2.12)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->bnlp_toolkit) (6.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp_toolkit) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp_toolkit) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->bnlp_toolkit) (2023.6.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp_toolkit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp_toolkit) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp_toolkit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bnlp_toolkit) (2023.7.22)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (0.9.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (1.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (0.9.0)\n",
            "Collecting fasttext==0.9.2\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext==0.9.2)\n",
            "  Using cached pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext==0.9.2) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext==0.9.2) (1.23.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4199773 sha256=e010ca65bc3fef39cf2a6bcfcc75a3d62a28c1afbc76b6593d3b11e67eacc5fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.11.1\n",
            "Requirement already satisfied: schedule in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install bnlp_toolkit\n",
        "!pip install fasttext==0.9.2\n",
        "!pip install schedule\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Requirements:\n",
        "##### The following two cells imports the libraries, and prepares the model and other files/folders required to run the sentiment prediction program.\n",
        "\n",
        "##### Pleae reffer to the comments for adjusting the variables and, commenenting out unnecessary lines, based the system used for running this code"
      ],
      "metadata": {
        "id": "SrWuuauxdcfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.svm import SVC\n",
        "from pickle import dump, load\n",
        "from bnlp import NLTKTokenizer\n",
        "from bnlp.embedding.fasttext import BengaliFasttext\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import datetime\n",
        "import pytz\n",
        "import os\n",
        "import os.path\n",
        "import re\n",
        "import threading\n",
        "import schedule\n",
        "import time\n",
        "from zipfile import ZipFile\n",
        "from bnlp import BengaliCorpus as corpus\n",
        "from bnlp import CleanText\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# please comment out the following three lines if not running this file on colab\n",
        "from google.colab import files\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n",
        "class MakeModel(nn.Module):\n",
        "  def __init__(self,model,k):\n",
        "    super(MakeModel,self).__init__()\n",
        "    self.bert_model=model\n",
        "    self.lin_layer=nn.Linear(768,k)\n",
        "\n",
        "  def forward(self,input_ids,attention_mask):\n",
        "    out_vect=self.bert_model(input_ids=input_ids,attention_mask=attention_mask)\n",
        "    lin_op=self.lin_layer(out_vect.last_hidden_state[:,0,:])\n",
        "    return F.softmax(lin_op)\n",
        "\n",
        "\n",
        "bnltk = NLTKTokenizer()\n",
        "os.mkdir('results')\n",
        "DEVICE=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYDaxuay3BmM",
        "outputId": "7b5bb618-b5d9-4e8f-fedb-245cfdcc38bf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "punkt not found. downloading...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# either of the following two finetuned models can be used or the third SVC model can be used\n",
        "\n",
        "# model 1\n",
        "# model_name = 'csebuetnlp/banglabert'\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# PATH = '/content/drive/MyDrive/Bangla_SA/bsenti_model3.pt'       # please adjust this path based on model's storage location\n",
        "# model = torch.load(PATH)\n",
        "# model.to(DEVICE)\n",
        "\n",
        "# model 2\n",
        "# model_name = 'sagorsarker/bangla-bert-base'\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# PATH = '/content/drive/MyDrive/Bangla_SA/bsenti_model.pt'       # please adjust this path based on model's storage location\n",
        "# model = torch.load(PATH)\n",
        "# model.to(DEVICE)\n",
        "\n",
        "# model 3\n",
        "tokenizer, model = None, None\n",
        "bft = BengaliFasttext()\n",
        "f2=open('/content/svc_model.pkl','rb')                         # please comment out the above two model if wish to use this model\n",
        "clf = load(f2)\n",
        "f2.close()\n",
        "\n",
        "\n",
        "# please modify the below two paths accorsing to your system\n",
        "dir_path_in = '/content'           # stores input: directory in which the json files of news articles will be present\n",
        "dir_path_out = '/content/results'           # stores output: oudirectory in which the generated sentiment analysis json files are present\n",
        "\n",
        "\n",
        "# the follwoing two lines extracts a sample of 100 news articles json files and adds them to the input directory of news articles\n",
        "# comment out the following two lines if you don't want to extract files from news_sample.zip or don't have any such zipfile\n",
        "articles_fl = \"news_sample.zip\"    # you may also modify this varible if you have any other zipfile\n",
        "with ZipFile(articles_fl, 'r') as zObject:\n",
        "  zObject.extractall(path=dir_path_in)\n",
        "\n",
        "\n",
        "files_list_in = os.listdir(dir_path_in)\n",
        "files_list_out = os.listdir(dir_path_out)\n",
        "\n",
        "stopwords = corpus.stopwords\n",
        "punct = [p for p in corpus.punctuations]\n",
        "punct2 = punct[:-2]\n",
        "bsw_df = pd.read_excel('stopwords_bangla.xlsx')\n",
        "sw2 = list(bsw_df['words'])\n",
        "stopwords.extend(sw2)\n",
        "stopwords = sorted(list(set(stopwords)))\n",
        "clean_text = CleanText(\n",
        "   fix_unicode=True,\n",
        "   unicode_norm=True,\n",
        "   unicode_norm_form=\"NFKC\",\n",
        "   remove_url=True,\n",
        "   remove_email=True,\n",
        "   remove_emoji=True,\n",
        "   remove_number=True,\n",
        "   remove_digits=True,\n",
        "   remove_punct=False,\n",
        "   replace_with_url=\" \",\n",
        "   replace_with_email=\" \",\n",
        "   replace_with_number=\" \",\n",
        "   replace_with_digit=\" \")\n"
      ],
      "metadata": {
        "id": "BcWqPN-WoP-c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "903706d4-35aa-42db-94fd-8eb7a44aaec5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code for output generation\n",
        "##### Please choose the required get_sentiment method in the predict() method and comment out the other in the two places they are invoked"
      ],
      "metadata": {
        "id": "MYaJFVGtdJyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment(sent):\n",
        "  tokenized_path = tokenizer(sent,truncation=True,padding=True,max_length=500,return_tensors='pt').to(DEVICE)\n",
        "  input_ids,attn_mask = tokenized_path['input_ids'],tokenized_path['attention_mask']\n",
        "  out_vals=model(input_ids,attn_mask)\n",
        "  labl=torch.argmax(out_vals,1)\n",
        "  out_list=out_vals.detach().cpu().numpy().tolist()\n",
        "  label_dict = {0:'Negative', 1:'Positive', 2:'Neutral'}\n",
        "  output_dict=dict()\n",
        "  for i in range(len(out_list[0])):\n",
        "    output_dict[label_dict[i]]= round(out_list[0][i],3)\n",
        "  return output_dict\n",
        "\n",
        "\n",
        "def get_sentiment_svm(sent):\n",
        "  testX = bft.get_word_vector(sent)\n",
        "  pred_prob = clf.predict_proba([testX])\n",
        "  prob = list(pred_prob[0])\n",
        "  prob = [round(p,3) for p in prob]\n",
        "  output_dict = {'Negative':prob[0], 'Positive':prob[1], 'Neutral':prob[2]}\n",
        "  return output_dict\n",
        "\n",
        "\n",
        "def predict(text,cat):               # please comment out either of the get_sentiment call based on the model you are using\n",
        "  sents = bnltk.sentence_tokenize(text)\n",
        "  res_dict = dict()\n",
        "  for st in sents:\n",
        "    # curr_dict2 = get_sentiment(st)\n",
        "    curr_dict2 = get_sentiment_svm(st)\n",
        "    if len(res_dict.keys()) == 0:\n",
        "      res_dict = curr_dict2.copy()\n",
        "    else:\n",
        "      for k in curr_dict2.keys():\n",
        "        res_dict[k] = res_dict[k] + curr_dict2[k]\n",
        "  for k in res_dict.keys():\n",
        "    res_dict[k] = round((res_dict[k]/len(sents)),3)\n",
        "  # curr_dict2 = get_sentiment(text)\n",
        "  curr_dict2 = get_sentiment_svm(text)\n",
        "  for k in curr_dict2.keys():\n",
        "    res_dict[k] = res_dict[k] + curr_dict2[k]\n",
        "  for k in res_dict.keys():\n",
        "    res_dict[k] = round((res_dict[k]/2),3)\n",
        "  senti, val = None, -1\n",
        "  for k in res_dict.keys():\n",
        "    if res_dict[k] > val:\n",
        "      val = res_dict[k]\n",
        "      senti = k\n",
        "  res_dict['Sentiment'] = senti\n",
        "  res_dict['Category'] = cat\n",
        "  current_time = datetime.datetime.now(pytz.timezone('Asia/Kolkata'))\n",
        "  date = str(current_time.day) + '/' + str(current_time.month) + '/' + str(current_time.year)\n",
        "  time = str(current_time.hour) + ':' + str(current_time.minute) + ':' + str(current_time.second)\n",
        "  res_dict['Date'] = date\n",
        "  res_dict['Time of generation'] = time\n",
        "  return res_dict\n",
        "\n",
        "\n",
        "def add_to_result(fl_name,content):\n",
        "  text = content['title'] + ' । ' + content['body']\n",
        "  pr_text = clean_text(text)\n",
        "  tokens = pr_text.split()\n",
        "  tokens = [t for t in tokens if t not in stopwords]\n",
        "  tokens = [t for t in tokens if t not in punct2]\n",
        "  pr_text2 = ' '.join(tokens)\n",
        "  pr_text2 = str(pr_text2)\n",
        "  cat = content['label']\n",
        "  res_dict = predict(pr_text2,cat)\n",
        "  fl_dir = dir_path_out + '/' + fl_name\n",
        "  with open(fl_dir, \"w\") as output:\n",
        "    json.dump(res_dict, output, indent=2)\n",
        "  print(f'\\nPredicted the sentiment of {fl_name} and added to the output directory !!! ')\n",
        "\n",
        "\n",
        "def download_result():       # call this function if running this code on colab and need to download all output files zipping together\n",
        "  zf = ZipFile(\"outputs.zip\", \"w\")\n",
        "  for dirname, subdirs, fles in os.walk(dir_path_out):\n",
        "      zf.write(dirname)\n",
        "      for filename in fles:\n",
        "          zf.write(os.path.join(dirname, filename))\n",
        "  zf.close()\n",
        "  files.download('/content/outputs.zip')\n",
        "\n",
        "\n",
        "def run_prediction():\n",
        "  files_list_in = os.listdir(dir_path_in)\n",
        "  files_list_in = [fl for fl in files_list_in if len(re.findall('\\.json',fl))==1]\n",
        "  files_list_out = os.listdir(dir_path_out)\n",
        "  new_files = list(set(files_list_in) - set(files_list_out))\n",
        "  n = len(new_files)\n",
        "  if n > 0:\n",
        "    i, j = 0, 0\n",
        "    while i < n:\n",
        "      threadpool = []\n",
        "      while i < n and j < 5:\n",
        "        fl = new_files[i]\n",
        "        fl_path = dir_path_in + '/' + fl\n",
        "        with open(fl_path, encoding='utf-8') as f:\n",
        "          content = json.load(f)\n",
        "        t = threading.Thread(target=add_to_result, args=(fl,content,))\n",
        "        threadpool.append(t)\n",
        "        i += 1\n",
        "        j += 1\n",
        "      for t in threadpool:\n",
        "        t.start()\n",
        "      for t in threadpool:\n",
        "        t.join()\n",
        "      if i < n:\n",
        "        j = 0\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "  count = 2  # modify the minutes count as per the requirement of how frequently the prediction function should be executed\n",
        "  schedule.every(count).minutes.do(run_prediction)\n",
        "  #schedule.every().hour.do(run_prediction)\n",
        "  while True:\n",
        "    schedule.run_pending()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8dBtJSrh9USC",
        "outputId": "5fb9f3f8-83e1-4cb3-d74a-e9efed3ce9d1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicted the sentiment of a27.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a75.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a63.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a91.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a50.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a47.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a46.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a16.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a21.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a38.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a35.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a100.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a76.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a33.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a83.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a2.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a30.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a12.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a57.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a18.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a25.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a19.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a88.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a67.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a84.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a43.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a86.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a69.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a53.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a92.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a24.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a95.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a8.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a66.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a98.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a15.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a56.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a41.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a31.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a59.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a13.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a22.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a99.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a87.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a64.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a39.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a93.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a49.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a74.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a78.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a28.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a48.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a82.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a3.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a80.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a89.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a40.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a10.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a45.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a32.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a20.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a37.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a36.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a81.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a70.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a96.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a94.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a1.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a72.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a85.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a52.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a97.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a71.json and added to the output directory !!! \n",
            "Predicted the sentiment of a42.json and added to the output directory !!! \n",
            "\n",
            "\n",
            "Predicted the sentiment of a9.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a68.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a61.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a5.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a55.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a17.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a29.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a79.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a4.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a34.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a51.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a58.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a73.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a90.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a23.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a77.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a60.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a11.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a26.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a65.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a62.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a54.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a44.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a14.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a6.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of a7.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of z3.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of z2.json and added to the output directory !!! \n",
            "\n",
            "Predicted the sentiment of z1.json and added to the output directory !!! \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-8ee30522ba86>\u001b[0m in \u001b[0;36m<cell line: 110>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m   \u001b[0;31m#schedule.every().hour.do(run_prediction)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mschedule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pending\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/schedule/__init__.py\u001b[0m in \u001b[0;36mrun_pending\u001b[0;34m()\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdefault\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mdefault_scheduler\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \"\"\"\n\u001b[0;32m--> 822\u001b[0;31m     \u001b[0mdefault_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pending\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/schedule/__init__.py\u001b[0m in \u001b[0;36mrun_pending\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[1;32m     98\u001b[0m         \u001b[0mrunnable_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunnable_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/schedule/__init__.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mbetween\u001b[0m \u001b[0mbut\u001b[0m \u001b[0monly\u001b[0m \u001b[0monce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mrunnable_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunnable_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/schedule/__init__.py\u001b[0m in \u001b[0;36mshould_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m         \"\"\"\n\u001b[1;32m    673\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_run\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"must run _schedule_next_run before\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files_list_out = os.listdir(dir_path_out)\n",
        "print(len(files_list_out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_WV81_zcfPY",
        "outputId": "db0f1607-f494-40b8-cb28-a2fa66dbd45e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run this to download a zip of the predicted files, if running code in google colab\n",
        "download_result()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "f_gyPMh4lkkr",
        "outputId": "7202504a-b661-4867-9415-d358821e1472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_aeb9c3e8-7c79-4204-a464-4388e446f7a3\", \"outputs.zip\", 33077)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}